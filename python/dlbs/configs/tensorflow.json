{
  "parameters": {
    "tensorflow.git_hashtag": {
      "val": "",
      "type": "str",
      "desc": [
        "A GitHub hash tag for tf_cnn_benchmark (https://github.com/tensorflow/benchmarks) i.e. for this benchmark backend.",
        "If empty, default is used that is the part of DLBS and that may be outdated. Newer versions can work faster, and you",
        "may want to try different versions. With specific versions, not all functionality may be available such as specific",
        "custom neural network models or advanced logging. I hope to fix this in the future.",
        "THIS IS NOT A HASH TAG for TensorFlow, this is a hash tag for TF_CNN_BENCHMARKS. In the upcoming update, this backend",
        "will be renamed to tfcnn and it will not be that confusing as it is now."
      ]
    },
    "tensorflow.launcher": {
      "val": "${DLBS_ROOT}/scripts/launchers/tensorflow_hpm.sh",
      "type": "str",
      "desc": "Path to a script that launches TensorFlow benchmarks."
    },
    "tensorflow.python_path": {
      "val": "$('${DLBS_ROOT}/python/tf_cnn_benchmarks${tensorflow.git_hashtag}' if ${exp.docker} is False else '/workspace/tf_cnn_benchmarks')$",
      "type": "str",
      "desc": "Path to a TensorFlow benchmarks python folder. Depends on if bare metal/docker based benchmark is requested."
    },
    "tensorflow.env": {
      "val": [
        "PYTHONPATH=${tensorflow.python_path}:\\$PYTHONPATH",
        "${runtime.EXPORT_CUDA_CACHE_PATH}",
        "${runtime.EXPORT_CUDA_VISIBLE_DEVICES}",
        "TF_DISABLE_CUDNN_TENSOR_OP_MATH=$('false' if ${exp.use_tensor_core} else 'true')$"
      ],
      "type": "str",
      "desc": "Environmental variables to set for TensorFlow benchmarks."
    },
    "tensorflow.var_update": {
      "val": "replicated",
      "type": "str",
      "desc": "This is a 'variable_update' parameter for tf_cnn_benchmarks. See tf_cnn_benchmarks.py for more details."
    },
    "tensorflow.use_nccl": {
      "val": true,
      "type": "bool",
      "desc": "This is a 'use_nccl' parameter for tf_cnn_benchmarks. See tf_cnn_benchmarks.py for more details."
    },
    "tensorflow.use_xla": {
      "val": false,
      "type": "bool",
      "desc": "Enable/disable XLA."
    },
    "tensorflow.use_mkl": {
      "val": false,
      "type": "bool",
      "desc": "If true, set MKL environment variables (--mkl parameter in tf_cnn_benchmarks)."
    },
    "tensorflow.local_parameter_device": {
      "val": "cpu",
      "type": "str",
      "desc": "This is a 'local_parameter_device' parameter for tf_cnn_benchmarks. See tf_cnn_benchmarks.py for more details."
    },
    "tensorflow.data_dir": {
      "val": "",
      "type": "str",
      "desc": [
        "A data directory if real data should be used. If empty, synthetic data is used (no data ingestion pipeline).",
        "See tf_cnn_benchmarks.py for more details."
      ]
    },
    "tensorflow.data_name": {
      "val": "",
      "type": "str",
      "desc": "This is a 'data_name' parameter for tf_cnn_benchmarks. See tf_cnn_benchmarks.py for more details."
    },
    "tensorflow.distortions": {
      "val": false,
      "type": "bool",
      "desc": "This is a 'distortions' parameter for tf_cnn_benchmarks. See tf_cnn_benchmarks.py for more details."
    },
    "tensorflow.num_intra_threads": {
      "val": 0,
      "type": "str",
      "desc": "This is a 'num_intra_threads' parameter for tf_cnn_benchmarks. See tf_cnn_benchmarks.py for more details."
    },
    "tensorflow.resize_method": {
      "val": "bilinear",
      "type": "str",
      "desc": "This is a 'resize_method' parameter for tf_cnn_benchmarks. See tf_cnn_benchmarks.py for more details."
    },
    "tensorflow.report_interval": {
      "val": "${exp.num_batches}",
      "type": "int",
      "desc": "Reporting interval - number of batches (same as '--display_every' parameter). Prints mean throughput and jitter."
    },
    "tensorflow.other_args": {
      "val": "",
      "type": "str",
      "desc": "Any other parameters to pass to tf_cnn_benchmarks that are not exposed directly by DLBS."
    },
    "tensorflow.args": {
      "val": [
        "--per_gpu_thread_count=1",
        "--xla=$('${tensorflow.use_xla}'.lower())$",
        "--use_fp16=$('true' if '${exp.dtype}' == 'float16' else 'false')$",
        "--use_tf_layers=true",
        "--staged_vars=false",
        "--model=${exp.model}",
        "--eval=false",
        "--forward_only=$('true' if '${exp.phase}'=='inference' else 'false')$",
        "--batch_size=${exp.replica_batch}",
        "--num_batches=${exp.num_batches}",
        "--num_warmup_batches=${exp.num_warmup_batches}",
        "$('--num_gpus=${exp.num_local_gpus}' if '${exp.device_type}' == 'gpu' else '')$",
        "--display_every=${tensorflow.report_interval}",
        "--device=${exp.device_type}",
        "--data_format=$('NCHW' if '${exp.device_type}' == 'gpu' else 'NHWC')$",
        "--variable_update=${tensorflow.var_update}",
        "$('--all_reduce_spec=nccl' if '${exp.device_type}' == 'gpu' and ${tensorflow.use_nccl} else '')$",
        "--local_parameter_device=${tensorflow.local_parameter_device}",
        "$('' if not '${exp.data_dir}' else '--data_dir=${exp.data_dir}' if ${exp.docker} is False else '--data_dir=/workspace/data')$",
        "$('--data_name=${tensorflow.data_name}' if '${tensorflow.data_name}' else '')$",
        "--distortions=$('true' if ${tensorflow.distortions} else 'false')$",
        "--num_intra_threads=${tensorflow.num_intra_threads}",
        "--resize_method=${tensorflow.resize_method}",
        "$('--mkl' if ${tensorflow.use_mkl} else '')$",
        "${tensorflow.other_args}"
      ],
      "type": "str",
      "desc": "These are a command line arguments passed to tf_cnn_benchmarks script."
    },
    "tensorflow.docker_image": {
      "val": "hpe/tensorflow:cuda9-cudnn7",
      "type": "str",
      "desc": "The name of a docker image to use for TensorFlow if containerized benchmark is requested."
    },
    "tensorflow.docker_args": {
      "val": [
        "-i",
        "--security-opt seccomp=unconfined",
        "--pid=host",
        "--volume=${DLBS_ROOT}/python/tf_cnn_benchmarks${tensorflow.git_hashtag}:/workspace/tf_cnn_benchmarks",
        "$('--volume=${runtime.cuda_cache}:/workspace/cuda_cache' if '${runtime.cuda_cache}' else '')$",
        "$('--volume=${exp.data_dir}:/workspace/data' if '${exp.data_dir}' else '')$",
        "$('--volume=${monitor.pid_folder}:/workspace/tmp' if ${monitor.frequency} > 0 else '')$",
        "${exp.docker_args}",
        "${exp.docker_image}"
      ],
      "type": "str",
      "desc": "In case if containerized benchmarks, this are the docker parameters."
    },
    "tensorflow.host_libpath": {
      "val": "",
      "type": "str",
      "desc": "Basically, it's a LD_LIBRARY_PATH for TensorFlow in case of a bare metal run."
    }
  },
  "extensions": [
    {
      "condition":{ "exp.framework": "tensorflow", "exp.docker": false },
      "parameters": { "tensorflow.env": [
        "PYTHONPATH=${tensorflow.python_path}:\\$PYTHONPATH",
        "${runtime.EXPORT_CUDA_CACHE_PATH}",
        "$('CUDA_CACHE_DISABLE=0' if '${runtime.cuda_cache}' else '')$",
        "$('CUDA_CACHE_MAXSIZE=2147483648' if '${runtime.cuda_cache}' else '')$",
        "${runtime.EXPORT_CUDA_VISIBLE_DEVICES}",
        "LD_LIBRARY_PATH=$('${tensorflow.host_libpath}:\\$LD_LIBRARY_PATH'.strip(' \t:'))$",
        "TF_DISABLE_CUDNN_TENSOR_OP_MATH=$('false' if ${exp.use_tensor_core} else 'true')$"
      ]}
    }
  ]
}
